# ü™ô Coding Challenge - Bitcoin Price
---

## üöÄ C√≥mo levantar el proyecto

1. Clona el repositorio:
```bash
git clone https://github.com/javieramayapat/konfio_data_challenge.git
cd konfio_data_challenge/
```

2. Duplica el archivo de entorno:
```bash
cp .env.example .env
```

3. Ub√≠cate dentro de la carpeta config-data-challenge y obt√©n la ruta absoluta con:
```bash
pwd
```

4.Copia esa ruta y p√©gala en la variable PATH_DEVELOP_SCRIPTS dentro del archivo .env.
Aseg√∫rate de que la ruta termine en /develop y que uses barras diagonales (/), por ejemplo:
```bash
PATH_DEVELOP_SCRIPTS=/home/usuario/ruta/proyecto/development
```

5. Verifica que la carpeta development/ exista dentro del proyecto para evitar errores al montar los vol√∫menes.Luego, puedes continuar con:

```bash
docker-compose up --build
```

Esto inicia:
- Un contenedor de PySpark + JupyterLab
- Una base de datos PostgreSQL
- El entorno se monta con rutas espec√≠ficas para warehouse/ (Iceberg) y drivers JDBC.

4. Abre el Jupyter Notebook:

- Navega a http://127.0.0.1:8888/lab
- Usa el toke del .env.example contenido en JUPYTER_TOKEN
- Abre el archivo: development/coding_challenge_bitcoin_price.ipynb
- Selecciona el kernel Python 3 y ejecuta run all

‚öôÔ∏è Tecnolog√≠as utilizadas
- PySpark (modo local)
- Apache Iceberg (formato lakehouse en S3 local)
- PostgreSQL (v√≠a Docker)
- CoinGecko API (demo key)
- JupyterLab (entorno interactivo)
- Docker & docker-compose
- Pre-commit + Ruff para formateo

## üìä Proceso t√©cnico

### üîß Diagrama de soluci√≥n local

![Soluci√≥n local en ejecuci√≥n](./images/Coding-Challenge-Bitcoin-Price-local-solution.png)

### 1. üõ†Ô∏è Extracci√≥n

Se utiliza la API de CoinGecko para obtener:

- Lista de criptomonedas disponibles
- Datos hist√≥ricos de Bitcoin durante Q1 de 2025

> ‚ö†Ô∏è **Limitaci√≥n**: la API demo solo permite acceder a datos del a√±o en curso. Por tanto, los datos de Q1 2025 se obtuvieron simulando una fecha actual dentro del mismo a√±o.

---

### 2. Transformaci√≥n

El proceso de transformaci√≥n fue dise√±ado para preparar los datos de CoinGecko para an√°lisis t√©cnico de forma precisa y estructurada. A continuaci√≥n se detallan las decisiones clave:

- **Conversi√≥n de timestamp en milisegundos a segundos:**  
  CoinGecko entrega los precios con `timestamp_ms` (milisegundos desde UNIX). Para poder convertirlos al tipo `timestamp` en PySpark y aplicar funciones de ventana, fue necesario dividirlos entre `1000`.

- **Creaci√≥n de la columna `event_date`:**  
  Como el an√°lisis t√©cnico requer√≠a calcular promedios m√≥viles por d√≠a, se cre√≥ una columna `event_date` extrayendo solo la fecha (`yyyy-MM-dd`) desde el `timestamp`. Esto permiti√≥ agrupar precios por d√≠a espec√≠fico y aplicar correctamente la ventana de 5 d√≠as ordenada cronol√≥gicamente.

- **Conservaci√≥n del `timestamp_ms` original:**  
  Aunque se gener√≥ un `timestamp` legible, se conserv√≥ el valor original en milisegundos para poder graficar la evoluci√≥n intrad√≠a del precio de Bitcoin con mayor granularidad.

- **Eliminaci√≥n de duplicados:**  
  Se aplic√≥ un `dropDuplicates()` sobre las columnas `timestamp_ms` y `price` para evitar registros duplicados entregados por la API.

- **C√°lculo del `daily_avg_price`:**  
  Para construir la media m√≥vil de 5 d√≠as, primero era necesario obtener un valor promedio por d√≠a. Agrupar directamente por `timestamp` no era viable, por lo que se us√≥ `event_date` para calcular el promedio diario.

- **C√°lculo de la `5-day moving average (sma_5d)`:**  
  Usando `event_date` como base, se aplic√≥ una funci√≥n de ventana ordenada por fecha para obtener una media m√≥vil de 5 d√≠as, la cual fue solicitada expl√≠citamente.

- **Uni√≥n final con metadata:**  
  Finalmente, se integraron las m√©tricas calculadas (`daily_avg_price`, `sma_5d`, `event_date`) con los datos de contexto provenientes del endpoint de CoinList como `coin_id`, `name` y `symbol`, resultando en un dataset unificado listo para an√°lisis y visualizaci√≥n.

---

### 3. üíæ Carga

Los resultados se almacenan en dos capas:

- **PostgreSQL** (para lectura relacional v√≠a JDBC)
- **Apache Iceberg** en la carpeta `warehouse/` (modelo lakehouse optimizado para consultas anal√≠ticas)


### 4. Visualizaci√≥n de precios extremos

Se cre√≥ una visualizaci√≥n que muestra la evoluci√≥n del precio de Bitcoin a lo largo del tiempo utilizando `timestamp_ms` como eje X y el precio como eje Y. Esto permite observar los picos de volatilidad con alta granularidad.  
Adem√°s, se identificaron de forma expl√≠cita:
- El **precio m√°ximo** detectado: `$108,228.27 USD`
- El **precio m√≠nimo** detectado: `$77,186.93 USD`  
Ambos ocurren dentro del primer trimestre de 2025, y permiten al analista identificar posibles zonas de entrada o salida en una estrategia de inversi√≥n.

![bitcoin max min annotation](./images/bitcoin_max_min_annotation.png)

### 5. An√°lisis t√©cnico con medias m√≥viles

Se aplic√≥ una metodolog√≠a de an√°lisis t√©cnico utilizando dos indicadores clave:

- **SMA diaria**: promedio del precio por d√≠a.
- **SMA de 5 d√≠as**: suaviza la serie para identificar tendencias sostenidas.

Ambas curvas se graficaron y se resaltaron visualmente:
- üü© **Verde**: cuando el promedio diario supera la SMA5 (tendencia alcista).
- üü• **Rojo**: cuando el promedio diario cae por debajo de la SMA5 (tendencia bajista).

**Observaciones clave:**
- En **enero 2025**, se detectaron periodos de crecimiento sostenido (tendencia alcista).
- A partir de **febrero**, la curva entra en fase bajista con cruces descendentes frecuentes.
- En **marzo**, se observ√≥ alta volatilidad y falta de direcci√≥n clara.

**Conclusi√≥n:**  
El an√°lisis sugiere que, tras un pico en enero, Bitcoin mostr√≥ se√±ales de correcci√≥n. La frecuencia de cruces bajistas indica una posible fase de consolidaci√≥n. No se recomienda una inversi√≥n inmediata a corto plazo, pero s√≠ monitoreo constante ante una posible reversi√≥n.

![bitcoin data analyst](./images/bitcoin_data_analyst.png)


## ‚öôÔ∏è Plan de Escalabilidad

Como plan de escalabilidad, propongo utilizar **AWS Lambda Functions** combinadas con una suscripci√≥n **PRO de CoinGecko API**, lo que nos permitir√° realizar extracciones de datos cada 5 minutos de forma m√°s estable. Dependiendo de los tipos de criptomonedas que deseemos mantener, se podr√° ajustar din√°micamente la lista de IDs.

Las credenciales de la API ser√°n gestionadas a trav√©s de **AWS Secrets Manager**, y recuperadas por la Lambda Function en tiempo de ejecuci√≥n. Una vez obtenidos los datos, se publicar√°n en **Kinesis Data Streams**, donde ser√°n procesados en tiempo real por **Apache Flink (Managed Service)**.

Flink se encargar√° de transformar los datos y guardarlos en un **bucket de S3** bajo el formato **Apache Iceberg**, el cual a su vez estar√° registrado en el **Glue Data Catalog** como una tabla de market data. A partir de ah√≠, la informaci√≥n podr√° consultarse desde **Athena** o visualizarse en **QuickSight**, permitiendo al equipo de anal√≠tica monitorear los precios y comportamientos por moneda.

Para la parte de despliegue, propongo trabajar con un enfoque de infraestructura como c√≥digo, utilizando **Terraform**, junto con **Git y Python** desde un repositorio en GitHub. A trav√©s de **GitHub Actions**, se podr√°n automatizar los despliegues de Lambdas, Flink Jobs y recursos definidos en Terraform.

Todos los componentes de AWS (Lambda, Kinesis, Flink, S3, Glue) estar√°n monitoreados mediante **CloudWatch**, y cada uno contar√° con su respectivo **IAM Role** configurado para mantener el principio de m√≠nimo privilegio y reforzar la seguridad.

Por √∫ltimo, en cuanto a gobernanza de datos, no se permitir√° que los usuarios finales definan las criptomonedas que desean analizar. En su lugar, cualquier nueva moneda deber√° ser solicitada al equipo de datos, quien validar√° su valor y pertinencia. Esto evita problemas de duplicaci√≥n, sobrecarga o inserci√≥n de IDs inv√°lidos, y asegura el control del costo y la calidad de la informaci√≥n procesada.

![plan de escalabilidad](./images/coding-challenge-bitcoin-price-scalability-plan.png)
